{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a31828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import re\n",
    "from scipy.linalg import norm\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_dir= './speech/'\n",
    "noise_dir= './noise/'\n",
    "sample_rate= 8000\n",
    "frame_length= 8064\n",
    "hop_length_frame= 8064\n",
    "n_fft= 255\n",
    "hop_length= 63\n",
    "SNR= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_noise_files = os.listdir(noise_dir)\n",
    "list_voice_files = os.listdir(voice_dir)\n",
    "nb_noise_files = len(list_noise_files)\n",
    "nb_noise_files = len(list_voice_files)\n",
    "nb_noise_files, nb_noise_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_audio_frame_stack(audio, frame_length, hop_length):\n",
    "    total_samples = len(audio)\n",
    "    frames = []\n",
    "    # Slide over the audio with the given hop length\n",
    "    for start in range(0, total_samples - frame_length + 1, hop_length):\n",
    "        frame = audio[start:start + frame_length]\n",
    "        frames.append(frame)\n",
    "    # Stack all frames vertically into a 2D array\n",
    "    frame_array = np.vstack(frames)\n",
    "    return frame_array\n",
    "\n",
    "def audio_files_to_numpy(audio_dir, list_audio_files, sample_rate, frame_length, hop_length_frame):\n",
    "    list_sound_array = []\n",
    "    for file in list_audio_files:\n",
    "        # open the audio file\n",
    "        y, sr = librosa.load(os.path.join(audio_dir, file), sr=sample_rate)\n",
    "        list_sound_array.append(audio_to_audio_frame_stack(y, frame_length, hop_length_frame))\n",
    "    return np.vstack(list_sound_array)\n",
    "\n",
    "def mixed_voice_with_noise(voice, noise, nb_samples, frame_length, SNR):\n",
    "    prod_voice = np.zeros((nb_samples, frame_length))\n",
    "    prod_noise = np.zeros((nb_samples, frame_length))\n",
    "    prod_noisy_voice = np.zeros((nb_samples, frame_length))\n",
    "\n",
    "    for i in range(nb_samples):\n",
    "        prod_voice[i, :] = voice[i, :]\n",
    "        prod_noise[i, :] = noise[i, :]/norm(noise[i, :])*10**(-SNR/20)*norm(voice[i, :]);\n",
    "        prod_noisy_voice[i, :] = prod_voice[i, :] + prod_noise[i, :]\n",
    "    return prod_voice, prod_noise, prod_noisy_voice\n",
    "\n",
    "def calculate_stft(n_fft, hop_length_fft, audio):\n",
    "    stftaudio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length_fft)\n",
    "    mag, phase= librosa.magphase(stftaudio)\n",
    "    return mag, phase\n",
    "\n",
    "def extract_stft_features(numpy_audio, dim_square_spec, n_fft, hop_length_fft):\n",
    "    nb_audio = numpy_audio.shape[0]\n",
    "    mag = np.zeros((nb_audio, dim_square_spec, dim_square_spec))\n",
    "    phase = np.zeros((nb_audio, dim_square_spec, dim_square_spec), dtype=complex)\n",
    "    for i in range(nb_audio):\n",
    "        mag[i, :, :], phase[i, :, :] = calculate_stft(n_fft, hop_length_fft, numpy_audio[i])\n",
    "    return mag, phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ffdd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting noise and voice from folder and convert to numpy\n",
    "noise = audio_files_to_numpy(noise_dir, list_noise_files, sample_rate, frame_length, hop_length_frame)\n",
    "voice = audio_files_to_numpy(voice_dir, list_voice_files, sample_rate, frame_length, hop_length_frame)\n",
    "voice.shape, noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6427cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.min([voice.shape[0], noise.shape[0]])\n",
    "voice= voice[0:l]\n",
    "noise= noise[0:l]\n",
    "voice.shape, noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf0b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squared spectrogram dimensions\n",
    "dim_square_spec = int(n_fft / 2) + 1 \n",
    "dim_square_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('sound')\n",
    "nb_samples= voice.shape[0]\n",
    "nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef10d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_voice, prod_noise, prod_noisy = mixed_voice_with_noise(voice, noise, nb_samples, frame_length, SNR)\n",
    "del voice, noise\n",
    "voice= prod_voice.reshape(1, nb_samples*frame_length)\n",
    "noise= prod_noise.reshape(1, nb_samples*frame_length)\n",
    "noisy= prod_noisy.reshape(1, nb_samples*frame_length)\n",
    "\n",
    "sf.write('./sound/voice.wav', voice[0, :], samplerate= sample_rate)\n",
    "sf.write('./sound/noise.wav', noise[0, :], samplerate= sample_rate)\n",
    "sf.write('./sound/noisy.wav', noisy[0, :], samplerate= sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_mag, voice_phase= extract_stft_features(prod_voice, dim_square_spec, n_fft, hop_length)\n",
    "del prod_voice\n",
    "noise_mag, noise_phase= extract_stft_features(prod_noise, dim_square_spec, n_fft, hop_length)\n",
    "del prod_noise\n",
    "noisy_mag, noisy_phase= extract_stft_features(prod_noisy, dim_square_spec, n_fft, hop_length)\n",
    "del prod_noisy\n",
    "os.makedirs('spectrogram_data')\n",
    "voice_mag.shape, voice_phase.shape, noise_mag.shape, noise_phase.shape, noisy_mag.shape, noisy_phase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41724605",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_mag = voice_mag.reshape(voice_mag.shape[0],voice_mag.shape[1],voice_mag.shape[2],1)\n",
    "voice_phase = voice_phase.reshape(voice_phase.shape[0],voice_phase.shape[1],voice_phase.shape[2],1)\n",
    "\n",
    "noise_mag = noise_mag.reshape(noise_mag.shape[0],noise_mag.shape[1],noise_mag.shape[2],1)\n",
    "noise_phase = noise_phase.reshape(noise_phase.shape[0],noise_phase.shape[1],noise_phase.shape[2],1)\n",
    "\n",
    "noisy_mag = noisy_mag.reshape(noisy_mag.shape[0],noisy_mag.shape[1],noisy_mag.shape[2],1)\n",
    "noisy_phase = noisy_phase.reshape(noisy_phase.shape[0],noisy_phase.shape[1],noisy_phase.shape[2],1)\n",
    "voice_mag.shape, voice_phase.shape, noise_mag.shape, noise_phase.shape, noisy_mag.shape, noisy_phase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fd230",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./spectrogram_data/voice_mag', voice_mag)\n",
    "np.save('./spectrogram_data/voice_phase', voice_phase)\n",
    "np.save('./spectrogram_data/noise_mag', noise_mag)\n",
    "np.save('./spectrogram_data/noise_phase', noise_phase)\n",
    "np.save('./spectrogram_data/noisy_mag', noisy_mag)\n",
    "np.save('./spectrogram_data/noisy_phase', noisy_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653b231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
